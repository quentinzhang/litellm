{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZx-wHJapG5w"
      },
      "source": [
        "# Use liteLLM to call ChatCLM models\n",
        "\n",
        "* chatglm_turbo: https://github.com/zhipuai/zhipuai-sdk-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4JSRa0QVogPo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchainplus-sdk (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -iktoken (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting litellm==0.1.399\n",
            "  Obtaining dependency information for litellm==0.1.399 from https://files.pythonhosted.org/packages/f0/bf/cf8c16b5102c31cbbee667653d0f491a19ceec2c2a40fe4de2894c4b1015/litellm-0.1.399-py3-none-any.whl.metadata\n",
            "  Downloading litellm-0.1.399-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: openai<0.28.0,>=0.27.8 in /usr/local/lib/python3.9/site-packages (from litellm==0.1.399) (0.27.8)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from litellm==0.1.399) (1.0.0)\n",
            "Collecting tiktoken<0.5.0,>=0.4.0 (from litellm==0.1.399)\n",
            "  Using cached tiktoken-0.4.0-cp39-cp39-macosx_10_9_x86_64.whl (798 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/site-packages (from openai<0.28.0,>=0.27.8->litellm==0.1.399) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from openai<0.28.0,>=0.27.8->litellm==0.1.399) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/site-packages (from openai<0.28.0,>=0.27.8->litellm==0.1.399) (3.8.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/site-packages (from tiktoken<0.5.0,>=0.4.0->litellm==0.1.399) (2022.8.17)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.8->litellm==0.1.399) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.8->litellm==0.1.399) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.8->litellm==0.1.399) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.8->litellm==0.1.399) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->litellm==0.1.399) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->litellm==0.1.399) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->litellm==0.1.399) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->litellm==0.1.399) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->litellm==0.1.399) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->litellm==0.1.399) (1.3.1)\n",
            "Downloading litellm-0.1.399-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m665.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -angchainplus-sdk (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -iktoken (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: tiktoken, litellm\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.5.1\n",
            "    Uninstalling tiktoken-0.5.1:\n",
            "      Successfully uninstalled tiktoken-0.5.1\n",
            "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m  Attempting uninstall: litellm\n",
            "    Found existing installation: litellm 0.12.5\n",
            "    Uninstalling litellm-0.12.5:\n",
            "      Successfully uninstalled litellm-0.12.5\n",
            "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed litellm-0.1.399 tiktoken-0.4.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchainplus-sdk (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -iktoken (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting zhipu\n",
            "  Downloading zhipu-1.0.1-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from zhipu) (2.31.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.9/site-packages (from zhipu) (3.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests->zhipu) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->zhipu) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->zhipu) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->zhipu) (2023.7.22)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -angchainplus-sdk (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -iktoken (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: zhipu\n",
            "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed zhipu-1.0.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install litellm==0.1.399\n",
        "!pip install zhipu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VEukLhDzo4vw"
      },
      "outputs": [],
      "source": [
        "import zhipu\n",
        "import litellm\n",
        "import os\n",
        "from litellm import completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4STYM2OHFNlc"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DorpLxw1FHbC"
      },
      "outputs": [],
      "source": [
        "os.environ['ZHIPU_API_KEY'] = \"38dc046c622b6ec1b9bfa0413e6ca2ee.2Yn3uFr8j74pMOvK\" #@param\n",
        "messages = [{ \"content\": \"你好！\",\"role\": \"user\"}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syF3dTdKFSQQ"
      },
      "source": [
        "## Calling ChatCLM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPgSoMlsojz0",
        "outputId": "81d6dc7b-1681-4ae4-e4c8-5684eb1bd050"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m API key set.\n",
            "INFO:baseten:API key set.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'choices': [{'finish_reason': 'stop',\n",
              "   'index': 0,\n",
              "   'message': {'role': 'assistant',\n",
              "    'content': \"what does Baseten do? \\nI'm sorry, I cannot provide a specific answer as\"}}],\n",
              " 'created': 1692135883.699066,\n",
              " 'model': 'qvv0xeq'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = \"qvv0xeq\"\n",
        "response = completion(model=model, messages=messages, custom_llm_provider=\"baseten\")\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n21UroEGCGa"
      },
      "source": [
        "## Calling Wizard LM https://app.baseten.co/explore/wizardlm\n",
        "### Pass Your Baseten model `Version ID` as `model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLVWFH899lAF",
        "outputId": "61c2bc74-673b-413e-bb40-179cf408523d"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "argument of type 'NoneType' is not iterable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/private/var/www/litellm/cookbook/liteLLM_ChatCLM.ipynb 单元格 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/private/var/www/litellm/cookbook/liteLLM_ChatCLM.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mchatglm_turbo\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/private/var/www/litellm/cookbook/liteLLM_ChatCLM.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m response \u001b[39m=\u001b[39m completion(model\u001b[39m=\u001b[39;49mmodel, messages\u001b[39m=\u001b[39;49mmessages)\n\u001b[1;32m      <a href='vscode-notebook-cell:/private/var/www/litellm/cookbook/liteLLM_ChatCLM.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(response)\n\u001b[1;32m      <a href='vscode-notebook-cell:/private/var/www/litellm/cookbook/liteLLM_ChatCLM.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m response\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/litellm/utils.py:158\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m my_thread \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mThread(target\u001b[39m=\u001b[39mhandle_failure, args\u001b[39m=\u001b[39m(e, traceback_exception, start_time, end_time, args, kwargs)) \u001b[39m# don't interrupt execution of main thread\u001b[39;00m\n\u001b[1;32m    157\u001b[0m my_thread\u001b[39m.\u001b[39mstart()\n\u001b[0;32m--> 158\u001b[0m \u001b[39mraise\u001b[39;00m e\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/litellm/utils.py:145\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m## MODEL CALL\u001b[39;00m\n\u001b[1;32m    144\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m--> 145\u001b[0m result \u001b[39m=\u001b[39m original_function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    146\u001b[0m end_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m    147\u001b[0m \u001b[39m## LOG SUCCESS \u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/litellm/timeout.py:44\u001b[0m, in \u001b[0;36mtimeout.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     local_timeout_duration \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mforce_timeout\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     result \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mlocal_timeout_duration)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m futures\u001b[39m.\u001b[39mTimeoutError:\n\u001b[1;32m     46\u001b[0m     thread\u001b[39m.\u001b[39mstop_loop()\n",
            "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:445\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    444\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    446\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
            "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/litellm/timeout.py:35\u001b[0m, in \u001b[0;36mtimeout.<locals>.decorator.<locals>.wrapper.<locals>.async_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39masync_func\u001b[39m():\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/litellm/main.py:486\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, functions, function_call, temperature, top_p, n, stream, stop, max_tokens, presence_penalty, frequency_penalty, logit_bias, user, deployment_id, return_async, api_key, force_timeout, logger_fn, verbose, azure, custom_llm_provider, custom_api_base, top_k, request_timeout)\u001b[0m\n\u001b[1;32m    484\u001b[0m logging(model\u001b[39m=\u001b[39mmodel, \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mmessages, custom_llm_provider\u001b[39m=\u001b[39mcustom_llm_provider, additional_args\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmax_tokens\u001b[39m\u001b[39m\"\u001b[39m: max_tokens}, logger_fn\u001b[39m=\u001b[39mlogger_fn, exception\u001b[39m=\u001b[39me)\n\u001b[1;32m    485\u001b[0m \u001b[39m## Map to OpenAI Exception\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m \u001b[39mraise\u001b[39;00m exception_type(model\u001b[39m=\u001b[39;49mmodel, custom_llm_provider\u001b[39m=\u001b[39;49mcustom_llm_provider, original_exception\u001b[39m=\u001b[39;49me)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/litellm/utils.py:663\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider)\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    662\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39m# don't let an error with mapping interrupt the user from receiving an error from the llm api calls \u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m    \u001b[39mraise\u001b[39;00m original_exception\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/litellm/utils.py:654\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider)\u001b[0m\n\u001b[1;32m    652\u001b[0m           exception_mapping_worked \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    653\u001b[0m           \u001b[39mraise\u001b[39;00m RateLimitError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHuggingfaceException - \u001b[39m\u001b[39m{\u001b[39;00moriginal_exception\u001b[39m.\u001b[39mmessage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 654\u001b[0m   \u001b[39mraise\u001b[39;00m original_exception \u001b[39m# base case - return the original exception\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m   \u001b[39mraise\u001b[39;00m original_exception\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/litellm/main.py:459\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, functions, function_call, temperature, top_p, n, stream, stop, max_tokens, presence_penalty, frequency_penalty, logit_bias, user, deployment_id, return_async, api_key, force_timeout, logger_fn, verbose, azure, custom_llm_provider, custom_api_base, top_k, request_timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m   model_response[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\n\u001b[1;32m    457\u001b[0m   response \u001b[39m=\u001b[39m model_response\n\u001b[0;32m--> 459\u001b[0m \u001b[39melif\u001b[39;00m custom_llm_provider \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpetals\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39;49m\u001b[39mchat.petals.dev\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39min\u001b[39;49;00m litellm\u001b[39m.\u001b[39;49mapi_base:\n\u001b[1;32m    460\u001b[0m   url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://chat.petals.dev/api/v1/generate\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m   \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
          ]
        }
      ],
      "source": [
        "model = \"chatglm_turbo\"\n",
        "response = completion(model=model, messages=messages)\n",
        "print(response)\n",
        "response"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
